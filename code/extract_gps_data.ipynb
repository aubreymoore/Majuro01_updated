{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intended-egypt",
   "metadata": {},
   "source": [
    "# extract_gps_data.ipynb\n",
    "\n",
    "* 2023-04-09 Timestamp extracted from image filename instead of EXIF. An attempt to fix infrequent errors (2 out of 20000) in timestamp provided by EXIF\n",
    "* 2022-12-03 Added error handling for when no image files are found\n",
    "* 2022-09-04 Added error handling code which deletes images from which gps coordinates cannot be extracted\n",
    "* 2021-11-20 Fixed problems in get_gps_coordinates()\n",
    "* 2021-05-06 Added code to adjust coordinates using rolling averages\n",
    "* 2021-05-02 First version by Aubrey Moore\n",
    "\n",
    "Extracts geotagging data from EXIF tags stored in one or more image files.\n",
    "\n",
    "Example usage:\n",
    "\n",
    "    papermill extract_gps_data.ipynb \\\n",
    "    '../output/extract_gps_data_output.ipynb' \\\n",
    "    -p IMAGE_FILE_PATH '../rawdata/*.jpg' \\\n",
    "    -p CSV_OUTPUT_FILE '../rawdata/gps-data.csv'\n",
    "    \n",
    "When the above command line is executed in the directory containing **extract_gps_data.ipynb**, \n",
    "GPS data will be extracted from all **jpg** files in the **IMAGE_FILE_PATH** and results will be saved in \n",
    "**CSV_OUTPUT_FILE**.\n",
    "\n",
    "\n",
    "2022-09-03T05:46:57+1000 [ERROR] create_dataframe Could not get gps coordinates from ../rawdata/IMG_20220221_112311.jpg; image ignored\n",
    "\n",
    "## References\n",
    "\n",
    "https://developer.here.com/blog/getting-started-with-geocoding-exif-image-metadata-in-python3\n",
    "\n",
    "http://www.50northspatial.org/using-open-camera-geotagging-photos/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "located-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS, GPSTAGS\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incorporate-rochester",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters for papermill\n",
    "\n",
    "IMAGE_FILE_PATH = '../rawdata/*.jpg'         # Path to one or more image files. Can include wildcards. See https://pymotw.com/2/glob/ for pattern matching details.\n",
    "CSV_OUTPUT_FILE = '../rawdata/gps-data.csv'  # Path to a CSV file where the GPS data will be stored. \n",
    "ADJUST_COORDINATES = True\n",
    "MAKE_MAPS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unsigned-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exif(filename):\n",
    "    image = Image.open(filename)\n",
    "    image.verify()\n",
    "    return image._getexif()\n",
    "\n",
    "\n",
    "def get_geotagging(exif):\n",
    "    if not exif:\n",
    "        raise ValueError(\"No EXIF metadata found\")\n",
    "    geotagging = {}\n",
    "    for (idx, tag) in TAGS.items():\n",
    "        if tag == 'GPSInfo':\n",
    "            if idx not in exif:\n",
    "                raise ValueError(\"No EXIF geotagging found\")\n",
    "            for (key, val) in GPSTAGS.items():\n",
    "                if key in exif[idx]:\n",
    "                    geotagging[val] = exif[idx][key]\n",
    "    return geotagging\n",
    "\n",
    "\n",
    "def get_gps_coordinates(image_file_name):\n",
    "    exif = get_exif(image_file_name)\n",
    "    gpsdata = get_geotagging(exif)\n",
    "        \n",
    "    d,m,s = gpsdata['GPSLatitude']\n",
    "    latitude = d + m/60.0 + s/3600.0\n",
    "    if gpsdata['GPSLatitudeRef']=='S':\n",
    "        latitude = -latitude\n",
    "    latitude = round(latitude, 6)\n",
    "\n",
    "    d,m,s = gpsdata['GPSLongitude']\n",
    "    longitude = d + m/60.0 + s/3600.0\n",
    "    if gpsdata['GPSLongitudeRef']=='W':\n",
    "        longitude = -longitude\n",
    "    longitude = round(longitude, 6)\n",
    "    \n",
    "# # Get timestamp from EXIF data    \n",
    "#     date = gpsdata['GPSDateStamp']\n",
    "#     date = date.replace(':', '-')\n",
    "#     h, m, s = gpsdata['GPSTimeStamp']\n",
    "#     timestamp = f'{date} {int(h):02}:{int(m):02}:{int(s):02}'\n",
    "\n",
    "    # get timestamp from filename\n",
    "    timestamp = os.path.basename(image_file_name).replace('IMG_', '').replace('.jpg', '')\n",
    "    timestamp = pd.to_datetime(timestamp, format='%Y%m%d_%H%M%S')\n",
    "    \n",
    "    return longitude, latitude, timestamp\n",
    "\n",
    "def create_dataframe():\n",
    "    # Get a sorted list of image files\n",
    "    image_files = sorted(glob.glob(IMAGE_FILE_PATH))\n",
    "    n = len(image_files)\n",
    "    \n",
    "    if n == 0:\n",
    "        raise Exception(f\"No image files were found in {IMAGE_FILE_PATH}\")\n",
    "\n",
    "    # Extract coordinates from each image file\n",
    "    df = pd.DataFrame(columns=['imagefile','longitude','latitude','timestamp'])\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        try:\n",
    "            longitude, latitude, timestamp = get_gps_coordinates(image_file)\n",
    "            df = df.append({'imagefile':os.path.basename(image_file),\n",
    "                            'longitude':longitude,\n",
    "                            'latitude':latitude,\n",
    "                            'timestamp':pd.to_datetime(timestamp)}, ignore_index=True) \n",
    "        except:\n",
    "#            os.remove(image_file) # WAY TOO RISKY. WHAT WAS I THINKING?\n",
    "            logging.error(f'Could not get gps coordinates from {image_file}; image deleted')\n",
    "        \n",
    "        if ((i+1) % 100 == 0):\n",
    "            logging.info(f'{i+1} of {n} images processed')\n",
    "                \n",
    "    return df \n",
    "\n",
    "\n",
    "def adjust_gps_coordinates():\n",
    "    '''\n",
    "    Calculates rolling averages for latitude and longitude to get better estimates for camera \n",
    "    positions and saves them in new columns: longitude_adjusted and latitude_adjusted. \n",
    "    This is a work-a-round for low precision GPS EXIF data data saved by the \n",
    "    OpenCamera app. For some reason, the app saves only degrees, minutes and seconds without decimal places. \n",
    "    This notebook calculates new points using 5-point rolling averages of latitude and longitude. \n",
    "    '''\n",
    "    df['time_diff'] = df[\"timestamp\"].diff().apply(lambda x: x/np.timedelta64(1,'s')).fillna(0).astype('int64')\n",
    "    \n",
    "    # Find location of segment breaks\n",
    "    # A new segment begins when an (image is taken is more than 60s after previous image\n",
    "\n",
    "    segments = []\n",
    "    segment_breaks = df.index[df['time_diff'] > 60].tolist()\n",
    "    segment_breaks.append(df.shape[0]) # Last index plus 1\n",
    "    for i, segment_break in enumerate(segment_breaks):\n",
    "        if i == 0:\n",
    "            start = 0\n",
    "        else:\n",
    "            start = segment_breaks[i-1]\n",
    "        segments.append({'first_index': start, 'last_index': segment_break-1})\n",
    "    logging.info(f'segments: {segments}')\n",
    "\n",
    "    # Calculate rolling averages to locations within each segment\n",
    "           \n",
    "    for segment in segments:\n",
    "        i1 = segment['first_index']\n",
    "        i2 = segment['last_index']\n",
    "        df.loc[i1:i2, 'longitude_adjusted'] = df.loc[i1:i2, 'longitude'].rolling(5, center=True, min_periods=1).mean() \n",
    "        df.loc[i1:i2, 'latitude_adjusted'] = df.loc[i1:i2, 'latitude'].rolling(5, center=True, min_periods=1).mean() \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "extended-conference",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20T10:09:46+0800 [INFO] <module> Starting georef.py\n",
      "2023-11-20T10:09:47+0800 [INFO] create_dataframe 100 of 13488 images processed\n",
      "2023-11-20T10:09:47+0800 [INFO] create_dataframe 200 of 13488 images processed\n",
      "2023-11-20T10:09:47+0800 [INFO] create_dataframe 300 of 13488 images processed\n",
      "2023-11-20T10:09:48+0800 [INFO] create_dataframe 400 of 13488 images processed\n",
      "2023-11-20T10:09:48+0800 [INFO] create_dataframe 500 of 13488 images processed\n",
      "2023-11-20T10:09:48+0800 [INFO] create_dataframe 600 of 13488 images processed\n",
      "2023-11-20T10:09:49+0800 [INFO] create_dataframe 700 of 13488 images processed\n",
      "2023-11-20T10:09:49+0800 [INFO] create_dataframe 800 of 13488 images processed\n",
      "2023-11-20T10:09:49+0800 [INFO] create_dataframe 900 of 13488 images processed\n",
      "2023-11-20T10:09:50+0800 [INFO] create_dataframe 1000 of 13488 images processed\n",
      "2023-11-20T10:09:50+0800 [INFO] create_dataframe 1100 of 13488 images processed\n",
      "2023-11-20T10:09:50+0800 [INFO] create_dataframe 1200 of 13488 images processed\n",
      "2023-11-20T10:09:51+0800 [INFO] create_dataframe 1300 of 13488 images processed\n",
      "2023-11-20T10:09:51+0800 [INFO] create_dataframe 1400 of 13488 images processed\n",
      "2023-11-20T10:09:51+0800 [INFO] create_dataframe 1500 of 13488 images processed\n",
      "2023-11-20T10:09:51+0800 [INFO] create_dataframe 1600 of 13488 images processed\n",
      "2023-11-20T10:09:52+0800 [INFO] create_dataframe 1700 of 13488 images processed\n",
      "2023-11-20T10:09:52+0800 [INFO] create_dataframe 1800 of 13488 images processed\n",
      "2023-11-20T10:09:52+0800 [INFO] create_dataframe 1900 of 13488 images processed\n",
      "2023-11-20T10:09:53+0800 [INFO] create_dataframe 2000 of 13488 images processed\n",
      "2023-11-20T10:09:53+0800 [INFO] create_dataframe 2100 of 13488 images processed\n",
      "2023-11-20T10:09:53+0800 [INFO] create_dataframe 2200 of 13488 images processed\n",
      "2023-11-20T10:09:54+0800 [INFO] create_dataframe 2300 of 13488 images processed\n",
      "2023-11-20T10:09:54+0800 [INFO] create_dataframe 2400 of 13488 images processed\n",
      "2023-11-20T10:09:54+0800 [INFO] create_dataframe 2500 of 13488 images processed\n",
      "2023-11-20T10:09:55+0800 [INFO] create_dataframe 2600 of 13488 images processed\n",
      "2023-11-20T10:09:55+0800 [INFO] create_dataframe 2700 of 13488 images processed\n",
      "2023-11-20T10:09:55+0800 [INFO] create_dataframe 2800 of 13488 images processed\n",
      "2023-11-20T10:09:56+0800 [INFO] create_dataframe 2900 of 13488 images processed\n",
      "2023-11-20T10:09:56+0800 [INFO] create_dataframe 3000 of 13488 images processed\n",
      "2023-11-20T10:09:56+0800 [INFO] create_dataframe 3100 of 13488 images processed\n",
      "2023-11-20T10:09:56+0800 [INFO] create_dataframe 3200 of 13488 images processed\n",
      "2023-11-20T10:09:57+0800 [INFO] create_dataframe 3300 of 13488 images processed\n",
      "2023-11-20T10:09:57+0800 [INFO] create_dataframe 3400 of 13488 images processed\n",
      "2023-11-20T10:09:57+0800 [INFO] create_dataframe 3500 of 13488 images processed\n",
      "2023-11-20T10:09:58+0800 [INFO] create_dataframe 3600 of 13488 images processed\n",
      "2023-11-20T10:09:58+0800 [INFO] create_dataframe 3700 of 13488 images processed\n",
      "2023-11-20T10:09:58+0800 [INFO] create_dataframe 3800 of 13488 images processed\n",
      "2023-11-20T10:09:59+0800 [INFO] create_dataframe 3900 of 13488 images processed\n",
      "2023-11-20T10:09:59+0800 [INFO] create_dataframe 4000 of 13488 images processed\n",
      "2023-11-20T10:09:59+0800 [INFO] create_dataframe 4100 of 13488 images processed\n",
      "2023-11-20T10:10:00+0800 [INFO] create_dataframe 4200 of 13488 images processed\n",
      "2023-11-20T10:10:00+0800 [INFO] create_dataframe 4300 of 13488 images processed\n",
      "2023-11-20T10:10:00+0800 [INFO] create_dataframe 4400 of 13488 images processed\n",
      "2023-11-20T10:10:01+0800 [INFO] create_dataframe 4500 of 13488 images processed\n",
      "2023-11-20T10:10:01+0800 [INFO] create_dataframe 4600 of 13488 images processed\n",
      "2023-11-20T10:10:01+0800 [INFO] create_dataframe 4700 of 13488 images processed\n",
      "2023-11-20T10:10:02+0800 [INFO] create_dataframe 4800 of 13488 images processed\n",
      "2023-11-20T10:10:02+0800 [INFO] create_dataframe 4900 of 13488 images processed\n",
      "2023-11-20T10:10:02+0800 [INFO] create_dataframe 5000 of 13488 images processed\n",
      "2023-11-20T10:10:03+0800 [INFO] create_dataframe 5100 of 13488 images processed\n",
      "2023-11-20T10:10:03+0800 [INFO] create_dataframe 5200 of 13488 images processed\n",
      "2023-11-20T10:10:03+0800 [INFO] create_dataframe 5300 of 13488 images processed\n",
      "2023-11-20T10:10:04+0800 [INFO] create_dataframe 5400 of 13488 images processed\n",
      "2023-11-20T10:10:04+0800 [INFO] create_dataframe 5500 of 13488 images processed\n",
      "2023-11-20T10:10:04+0800 [INFO] create_dataframe 5600 of 13488 images processed\n",
      "2023-11-20T10:10:05+0800 [INFO] create_dataframe 5700 of 13488 images processed\n",
      "2023-11-20T10:10:05+0800 [INFO] create_dataframe 5800 of 13488 images processed\n",
      "2023-11-20T10:10:05+0800 [INFO] create_dataframe 5900 of 13488 images processed\n",
      "2023-11-20T10:10:06+0800 [INFO] create_dataframe 6000 of 13488 images processed\n",
      "2023-11-20T10:10:06+0800 [INFO] create_dataframe 6100 of 13488 images processed\n",
      "2023-11-20T10:10:06+0800 [INFO] create_dataframe 6200 of 13488 images processed\n",
      "2023-11-20T10:10:06+0800 [INFO] create_dataframe 6300 of 13488 images processed\n",
      "2023-11-20T10:10:07+0800 [INFO] create_dataframe 6400 of 13488 images processed\n",
      "2023-11-20T10:10:07+0800 [INFO] create_dataframe 6500 of 13488 images processed\n",
      "2023-11-20T10:10:07+0800 [INFO] create_dataframe 6600 of 13488 images processed\n",
      "2023-11-20T10:10:08+0800 [INFO] create_dataframe 6700 of 13488 images processed\n",
      "2023-11-20T10:10:08+0800 [INFO] create_dataframe 6800 of 13488 images processed\n",
      "2023-11-20T10:10:08+0800 [INFO] create_dataframe 6900 of 13488 images processed\n",
      "2023-11-20T10:10:09+0800 [INFO] create_dataframe 7000 of 13488 images processed\n",
      "2023-11-20T10:10:09+0800 [INFO] create_dataframe 7100 of 13488 images processed\n",
      "2023-11-20T10:10:09+0800 [INFO] create_dataframe 7200 of 13488 images processed\n",
      "2023-11-20T10:10:10+0800 [INFO] create_dataframe 7300 of 13488 images processed\n",
      "2023-11-20T10:10:10+0800 [INFO] create_dataframe 7400 of 13488 images processed\n",
      "2023-11-20T10:10:10+0800 [INFO] create_dataframe 7500 of 13488 images processed\n",
      "2023-11-20T10:10:11+0800 [INFO] create_dataframe 7600 of 13488 images processed\n",
      "2023-11-20T10:10:11+0800 [INFO] create_dataframe 7700 of 13488 images processed\n",
      "2023-11-20T10:10:11+0800 [INFO] create_dataframe 7800 of 13488 images processed\n",
      "2023-11-20T10:10:11+0800 [INFO] create_dataframe 7900 of 13488 images processed\n",
      "2023-11-20T10:10:12+0800 [INFO] create_dataframe 8000 of 13488 images processed\n",
      "2023-11-20T10:10:12+0800 [INFO] create_dataframe 8100 of 13488 images processed\n",
      "2023-11-20T10:10:12+0800 [INFO] create_dataframe 8200 of 13488 images processed\n",
      "2023-11-20T10:10:13+0800 [INFO] create_dataframe 8300 of 13488 images processed\n",
      "2023-11-20T10:10:13+0800 [INFO] create_dataframe 8400 of 13488 images processed\n",
      "2023-11-20T10:10:13+0800 [INFO] create_dataframe 8500 of 13488 images processed\n",
      "2023-11-20T10:10:14+0800 [INFO] create_dataframe 8600 of 13488 images processed\n",
      "2023-11-20T10:10:14+0800 [INFO] create_dataframe 8700 of 13488 images processed\n",
      "2023-11-20T10:10:14+0800 [INFO] create_dataframe 8800 of 13488 images processed\n",
      "2023-11-20T10:10:15+0800 [INFO] create_dataframe 8900 of 13488 images processed\n",
      "2023-11-20T10:10:15+0800 [INFO] create_dataframe 9000 of 13488 images processed\n",
      "2023-11-20T10:10:15+0800 [INFO] create_dataframe 9100 of 13488 images processed\n",
      "2023-11-20T10:10:16+0800 [INFO] create_dataframe 9200 of 13488 images processed\n",
      "2023-11-20T10:10:16+0800 [INFO] create_dataframe 9300 of 13488 images processed\n",
      "2023-11-20T10:10:16+0800 [INFO] create_dataframe 9400 of 13488 images processed\n",
      "2023-11-20T10:10:16+0800 [INFO] create_dataframe 9500 of 13488 images processed\n",
      "2023-11-20T10:10:17+0800 [INFO] create_dataframe 9600 of 13488 images processed\n",
      "2023-11-20T10:10:17+0800 [INFO] create_dataframe 9700 of 13488 images processed\n",
      "2023-11-20T10:10:17+0800 [INFO] create_dataframe 9800 of 13488 images processed\n",
      "2023-11-20T10:10:18+0800 [INFO] create_dataframe 9900 of 13488 images processed\n",
      "2023-11-20T10:10:18+0800 [INFO] create_dataframe 10000 of 13488 images processed\n",
      "2023-11-20T10:10:18+0800 [INFO] create_dataframe 10100 of 13488 images processed\n",
      "2023-11-20T10:10:19+0800 [INFO] create_dataframe 10200 of 13488 images processed\n",
      "2023-11-20T10:10:19+0800 [INFO] create_dataframe 10300 of 13488 images processed\n",
      "2023-11-20T10:10:19+0800 [INFO] create_dataframe 10400 of 13488 images processed\n",
      "2023-11-20T10:10:20+0800 [INFO] create_dataframe 10500 of 13488 images processed\n",
      "2023-11-20T10:10:20+0800 [INFO] create_dataframe 10600 of 13488 images processed\n",
      "2023-11-20T10:10:20+0800 [INFO] create_dataframe 10700 of 13488 images processed\n",
      "2023-11-20T10:10:21+0800 [INFO] create_dataframe 10800 of 13488 images processed\n",
      "2023-11-20T10:10:21+0800 [INFO] create_dataframe 10900 of 13488 images processed\n",
      "2023-11-20T10:10:21+0800 [INFO] create_dataframe 11000 of 13488 images processed\n",
      "2023-11-20T10:10:21+0800 [INFO] create_dataframe 11100 of 13488 images processed\n",
      "2023-11-20T10:10:22+0800 [INFO] create_dataframe 11200 of 13488 images processed\n",
      "2023-11-20T10:10:22+0800 [INFO] create_dataframe 11300 of 13488 images processed\n",
      "2023-11-20T10:10:22+0800 [INFO] create_dataframe 11400 of 13488 images processed\n",
      "2023-11-20T10:10:23+0800 [INFO] create_dataframe 11500 of 13488 images processed\n",
      "2023-11-20T10:10:23+0800 [INFO] create_dataframe 11600 of 13488 images processed\n",
      "2023-11-20T10:10:23+0800 [INFO] create_dataframe 11700 of 13488 images processed\n",
      "2023-11-20T10:10:24+0800 [INFO] create_dataframe 11800 of 13488 images processed\n",
      "2023-11-20T10:10:24+0800 [INFO] create_dataframe 11900 of 13488 images processed\n",
      "2023-11-20T10:10:24+0800 [INFO] create_dataframe 12000 of 13488 images processed\n",
      "2023-11-20T10:10:25+0800 [INFO] create_dataframe 12100 of 13488 images processed\n",
      "2023-11-20T10:10:25+0800 [INFO] create_dataframe 12200 of 13488 images processed\n",
      "2023-11-20T10:10:25+0800 [INFO] create_dataframe 12300 of 13488 images processed\n",
      "2023-11-20T10:10:26+0800 [INFO] create_dataframe 12400 of 13488 images processed\n",
      "2023-11-20T10:10:26+0800 [INFO] create_dataframe 12500 of 13488 images processed\n",
      "2023-11-20T10:10:26+0800 [INFO] create_dataframe 12600 of 13488 images processed\n",
      "2023-11-20T10:10:26+0800 [INFO] create_dataframe 12700 of 13488 images processed\n",
      "2023-11-20T10:10:27+0800 [INFO] create_dataframe 12800 of 13488 images processed\n",
      "2023-11-20T10:10:27+0800 [INFO] create_dataframe 12900 of 13488 images processed\n",
      "2023-11-20T10:10:27+0800 [INFO] create_dataframe 13000 of 13488 images processed\n",
      "2023-11-20T10:10:28+0800 [INFO] create_dataframe 13100 of 13488 images processed\n",
      "2023-11-20T10:10:28+0800 [INFO] create_dataframe 13200 of 13488 images processed\n",
      "2023-11-20T10:10:28+0800 [INFO] create_dataframe 13300 of 13488 images processed\n",
      "2023-11-20T10:10:29+0800 [INFO] create_dataframe 13400 of 13488 images processed\n",
      "2023-11-20T10:10:29+0800 [INFO] <module> Adjusting coordinates\n",
      "2023-11-20T10:10:29+0800 [INFO] adjust_gps_coordinates segments: [{'first_index': 0, 'last_index': 13487}]\n",
      "2023-11-20T10:10:29+0800 [INFO] <module> FINISHED: Data saved in ../rawdata/gps-data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.5 s, sys: 545 ms, total: 42.1 s\n",
      "Wall time: 43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# MAIN\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(funcName)s %(message)s\",\n",
    "    datefmt=\"%Y-%m-%dT%H:%M:%S%z\",\n",
    "    handlers=[logging.StreamHandler()])\n",
    "logging.info('Starting georef.py')\n",
    "\n",
    "df = create_dataframe()\n",
    "\n",
    "if ADJUST_COORDINATES:\n",
    "    logging.info('Adjusting coordinates')\n",
    "    adjust_gps_coordinates()\n",
    "    \n",
    "df.to_csv(CSV_OUTPUT_FILE, index=False)\n",
    "logging.info(f'FINISHED: Data saved in {CSV_OUTPUT_FILE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "union-transmission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imagefile</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>time_diff</th>\n",
       "      <th>longitude_adjusted</th>\n",
       "      <th>latitude_adjusted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG_20231007_110603.jpg</td>\n",
       "      <td>171.366944</td>\n",
       "      <td>7.084722</td>\n",
       "      <td>2023-10-07 11:06:03</td>\n",
       "      <td>0</td>\n",
       "      <td>171.366944</td>\n",
       "      <td>7.084722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG_20231007_110604.jpg</td>\n",
       "      <td>171.366944</td>\n",
       "      <td>7.084722</td>\n",
       "      <td>2023-10-07 11:06:04</td>\n",
       "      <td>1</td>\n",
       "      <td>171.366944</td>\n",
       "      <td>7.084722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG_20231007_110605.jpg</td>\n",
       "      <td>171.366944</td>\n",
       "      <td>7.084722</td>\n",
       "      <td>2023-10-07 11:06:05</td>\n",
       "      <td>1</td>\n",
       "      <td>171.366944</td>\n",
       "      <td>7.084722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG_20231007_110606.jpg</td>\n",
       "      <td>171.366944</td>\n",
       "      <td>7.084722</td>\n",
       "      <td>2023-10-07 11:06:06</td>\n",
       "      <td>1</td>\n",
       "      <td>171.366944</td>\n",
       "      <td>7.084722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG_20231007_110608.jpg</td>\n",
       "      <td>171.366944</td>\n",
       "      <td>7.084722</td>\n",
       "      <td>2023-10-07 11:06:08</td>\n",
       "      <td>2</td>\n",
       "      <td>171.366944</td>\n",
       "      <td>7.084722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13483</th>\n",
       "      <td>IMG_20231007_150708.jpg</td>\n",
       "      <td>171.366944</td>\n",
       "      <td>7.084444</td>\n",
       "      <td>2023-10-07 15:07:08</td>\n",
       "      <td>1</td>\n",
       "      <td>171.366944</td>\n",
       "      <td>7.084444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13484</th>\n",
       "      <td>IMG_20231007_150709.jpg</td>\n",
       "      <td>171.366944</td>\n",
       "      <td>7.084444</td>\n",
       "      <td>2023-10-07 15:07:09</td>\n",
       "      <td>1</td>\n",
       "      <td>171.366944</td>\n",
       "      <td>7.084444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13485</th>\n",
       "      <td>IMG_20231007_150710.jpg</td>\n",
       "      <td>171.366944</td>\n",
       "      <td>7.084444</td>\n",
       "      <td>2023-10-07 15:07:10</td>\n",
       "      <td>1</td>\n",
       "      <td>171.366944</td>\n",
       "      <td>7.084444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13486</th>\n",
       "      <td>IMG_20231007_150711.jpg</td>\n",
       "      <td>171.366944</td>\n",
       "      <td>7.084444</td>\n",
       "      <td>2023-10-07 15:07:11</td>\n",
       "      <td>1</td>\n",
       "      <td>171.366944</td>\n",
       "      <td>7.084444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13487</th>\n",
       "      <td>IMG_20231007_150712.jpg</td>\n",
       "      <td>171.366944</td>\n",
       "      <td>7.084444</td>\n",
       "      <td>2023-10-07 15:07:12</td>\n",
       "      <td>1</td>\n",
       "      <td>171.366944</td>\n",
       "      <td>7.084444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13488 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     imagefile   longitude  latitude           timestamp  \\\n",
       "0      IMG_20231007_110603.jpg  171.366944  7.084722 2023-10-07 11:06:03   \n",
       "1      IMG_20231007_110604.jpg  171.366944  7.084722 2023-10-07 11:06:04   \n",
       "2      IMG_20231007_110605.jpg  171.366944  7.084722 2023-10-07 11:06:05   \n",
       "3      IMG_20231007_110606.jpg  171.366944  7.084722 2023-10-07 11:06:06   \n",
       "4      IMG_20231007_110608.jpg  171.366944  7.084722 2023-10-07 11:06:08   \n",
       "...                        ...         ...       ...                 ...   \n",
       "13483  IMG_20231007_150708.jpg  171.366944  7.084444 2023-10-07 15:07:08   \n",
       "13484  IMG_20231007_150709.jpg  171.366944  7.084444 2023-10-07 15:07:09   \n",
       "13485  IMG_20231007_150710.jpg  171.366944  7.084444 2023-10-07 15:07:10   \n",
       "13486  IMG_20231007_150711.jpg  171.366944  7.084444 2023-10-07 15:07:11   \n",
       "13487  IMG_20231007_150712.jpg  171.366944  7.084444 2023-10-07 15:07:12   \n",
       "\n",
       "       time_diff  longitude_adjusted  latitude_adjusted  \n",
       "0              0          171.366944           7.084722  \n",
       "1              1          171.366944           7.084722  \n",
       "2              1          171.366944           7.084722  \n",
       "3              1          171.366944           7.084722  \n",
       "4              2          171.366944           7.084722  \n",
       "...          ...                 ...                ...  \n",
       "13483          1          171.366944           7.084444  \n",
       "13484          1          171.366944           7.084444  \n",
       "13485          1          171.366944           7.084444  \n",
       "13486          1          171.366944           7.084444  \n",
       "13487          1          171.366944           7.084444  \n",
       "\n",
       "[13488 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "consolidated-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_MAPS:\n",
    "    fig = px.scatter_mapbox(df, lat=\"latitude\", lon=\"longitude\", title='Original coordinates', zoom=9)\n",
    "    fig.update_layout(mapbox_style=\"open-street-map\", margin={\"r\":0,\"t\":30,\"l\":0,\"b\":0})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "confident-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_MAPS and ADJUST_COORDINATES:\n",
    "    fig = px.scatter_mapbox(df, lat=\"latitude_adjusted\", lon=\"longitude_adjusted\", \n",
    "                            title='Adjusted coordinates', zoom=9)\n",
    "    fig.update_layout(mapbox_style=\"open-street-map\", margin={\"r\":0,\"t\":30,\"l\":0,\"b\":0})\n",
    "    fig.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "alone-punch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-10-07 11:06:03')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.timestamp.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rising-upset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-10-07 15:07:12')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.timestamp.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
